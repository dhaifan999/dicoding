# -*- coding: utf-8 -*-
"""PA_Dhaifan Satriaji_M128X0209.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MvPs5zl7NKmgB2lJCK4L8WtbZ1_95v7d

**Nama**  : Dhaifan Satriaji

**ID Siswa** : M128X0209

**Kelas** : M06
"""

# Commented out IPython magic to ensure Python compatibility.
import math
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import accuracy_score
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.model_selection import cross_val_score
from xgboost import XGBRegressor
from sklearn.pipeline import make_pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_selection import mutual_info_regression
from sklearn.decomposition import PCA

from google.colab import files
files.upload()

df.info()

btc_file_path = '../content/BTC-USD.csv'

df = pd.read_csv(btc_file_path)

y = df['Adj Close'] 

btc_features = ['Open','High', 'Low', 'Volume']
X = df[btc_features]
X.head()

df.isnull().values.any()

btc_model = LinearRegression()

btc_model.fit(X, y)

print("Making predicitons for the first 5 entries\n")
print(X.head())
print("\nThe predictions are:\n")
print(btc_model.predict(X.head()))
print("\nThe actual values are:\n")
print(y.head())

predicted_adj_close = btc_model.predict(X.head())
print(mean_absolute_error(y.head(),predicted_adj_close))

predicted_adj_close = btc_model.predict(X)
print(mean_absolute_error(y, predicted_adj_close))

train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0)
btc_model = LinearRegression()
btc_model.fit(train_X, train_y)

val_predictions = btc_model.predict(val_X)
print(mean_absolute_error(val_y,val_predictions))

btc_model = LinearRegression()

my_pipeline = Pipeline(steps=[('btc_model', btc_model)])
my_pipeline.fit(train_X, train_y)

preds = my_pipeline.predict(val_X)

mae_score = mean_absolute_error(val_y, preds)
print('MAE:', mae_score)

sns.regplot(x=val_y, y=preds, line_kws={"color":"black"})

scores = -1 * cross_val_score(my_pipeline, X, y,
                              cv=10,
                              scoring = 'neg_mean_absolute_error')
print("MAE scores:\n",scores,"\n")
print("Average MAE score (across all ten folds):")
print(scores.mean())

rmse = math.sqrt(mean_squared_error(val_y,preds))
print("\nRMSE is",rmse)

r2 = r2_score(val_y, preds)
print("\nr2 score is", r2)

my_model = XGBRegressor()
my_model.fit(train_X, train_y)

predictions = my_model.predict(val_X)
print("Mean Absolute Error: ",mean_absolute_error(predictions, val_y))

my_model = XGBRegressor(n_estimators=1000,
                        learning_rate=0.03,
                        n_jobs=4)
my_model.fit(train_X, train_y,
            early_stopping_rounds=5,
            eval_set=[(val_X, val_y)],
            verbose=False)

predictions = my_model.predict(val_X)
print("Mean Absolute Error",
      mean_absolute_error(predictions,val_y))

rmse = math.sqrt(mean_squared_error(val_y,predictions))
print("\nRMSE is", rmse)

r2 = r2_score(val_y,predictions)
print("\nr2 score is", r2)

sns.regplot(x=val_y, y=predictions, line_kws={"color": "black"})

plt.style.use("seaborn-whitegrid")

df.head()

X = df.copy()
y = X.pop('Adj Close')
date = X.pop('Date')
X.pop('Close')

def make_mi_scores (X, y):
    mi_scores = mutual_info_regression(X, y)
    mi_scores = pd.Series(mi_scores, name="MI Scores", index=X.columns)
    mi_scores = mi_scores.sort_values(ascending=False)
    return mi_scores

mi_scores = make_mi_scores(X, y)

def plot_mi_scores(scores):
    scores = scores.sort_values(ascending=True)
    width = np.arange(len(scores))
    ticks = list(scores.index)
    plt.barh(width, scores)
    plt.yticks(width, ticks)
    plt.title("Mutual Information Scores")
    
plt.figure(dpi=100, figsize=(10,18))
plot_mi_scores(mi_scores)

daily_high = sns.regplot(x="High", y="Adj Close", data=df, line_kws={"color": "black"}).set(title="Bitcoin's Daily High")

daily_low = sns.regplot(x="Low", y="Adj Close", data=df, line_kws={"color": "black"}).set(title="Bitcoin's Daily Low")

daily_close = sns.regplot(x="Open", y="Adj Close", data=df, line_kws={"color": "black"}).set(title="Bitcoin's Daily Open")

df["Daily_Change"] = abs(X.High - X.Low)

df['Date'] = pd.to_datetime(df['Date'], format = '%Y-%m-%d')

sns.set(rc={"figure.figsize":(20, 4)})
daily_change = sns.lineplot(x="Date", y="Daily_Change", data=df).set(title="Bitcoin's Daily Change/Volatility")

sns.set(rc={"figure.figsize":(20, 4)})
daily_change = sns.lineplot(x="Date", y="Adj Close", data=df).set(title="Bitcoin's Adjusted Daily Close Price")

features = ["High", "Low", "Open"]

X = df.copy()
y = X.pop('Adj Close')
date = X.pop('Date')
X.pop('Close')
X = X.loc[:, features]

X_scaled = (X - X.mean(axis=0)) / X.std(axis=0)

pca = PCA()
X_pca = pca.fit_transform(X_scaled)

component_names = [f"PC{i+1}" for i in range (X_pca.shape[1])]
X_pca = pd.DataFrame(X_pca, columns=component_names)

X_pca.head()

loadings = pd.DataFrame(
    pca.components_.T,       # Transpose the matrix of loadings
    columns=component_names, # to turn columns into principal components
    index = X.columns,       # and the rows are original features, so we can identify them
)
loadings

def plot_variance(pca, width=8, dpi=100):
    fig, axs = plt.subplots(1,2)
    n = pca.n_components_
    grid = np.arange(1, n + 1)
    
    evr = pca.explained_variance_ratio_
    axs[0].bar(grid, evr)
    axs[0].set(
        xlabel="Component", title="% Cumulative Variance", ylim=(0.0, 1.0)
    )
    cv = np.cumsum(evr)
    axs[1].plot(np.r_[0, grid], np.r_[0,cv], "o-")
    axs[1].set(
        xlabel="Component", title="%Cumulative Variance", ylim=(0.0,1.0)
    )
    fig.set(figwidth=8, dpi=100)
    return axs

plot_variance(pca);

mi_scores = make_mi_scores(X_pca, y)
mi_scores

train_X, val_X, train_y, val_y = train_test_split(X_pca, y, random_state = 0)

btc_model = LinearRegression()

my_pipeline = Pipeline(steps=[('btc_model', btc_model)])
my_pipeline.fit(train_X, train_y)

preds = my_pipeline.predict(val_X)

mae_score = mean_absolute_error(val_y, preds)
print('MAE:', mae_score)

sns.set(rc={"figure.figsize":(6,6)})
sns.regplot(x=val_y, y=preds, line_kws={"color":"black"}).set(title="Linear Regression with PCA")

scores = -1 * cross_val_score(my_pipeline, X_pca, y,
                              cv=10,
                              scoring = 'neg_mean_absolute_error')
print("MAE scores:\n",scores,"\n")
print("Average MAE score (across all ten folds):")
print(scores.mean())
rmse = math.sqrt(mean_squared_error(val_y,preds))
print("\nRMSE is", rmse)
r2 = r2_score(val_y,preds)
print("\nr2 score is", r2)

results = [['Linear Regression', 0.221, 0.326, 0.999672],
           ['Gradient Boosting (XGBoost)', 0.325, 0.490, 0.999259],
           ['Linear Regression with PCA', 0.193, 0.275, 0.999766]]
results_df = pd.DataFrame(results, columns = ['Model Type', 'MAE', 'RMSE', 'r2'])
results_df